{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA Compression for Point Cloud Data\n",
    "\n",
    "## Overview\n",
    "\n",
    "Principal Component Analysis (PCA) is a statistical method used to reduce the dimensionality of data while preserving as much variance as possible.  \n",
    "In the context of point cloud compression, PCA identifies the most significant directions of variation in the 3D data (principal components) and projects the points onto these axes. This reduces redundancy and minimizes storage size.\n",
    "\n",
    "---\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "### 1. Covariance Matrix\n",
    "\n",
    "PCA begins by computing the covariance matrix of the data, which measures how much each dimension varies with every other dimension.\n",
    "\n",
    "For a point cloud $X$ with dimensions $N \\times 3$ (points by dimensions):\n",
    "\n",
    "$$\n",
    "C = \\frac{1}{N-1} \\sum_{i=1}^{N} (X_i - \\mu) (X_i - \\mu)^T\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $C$: Covariance matrix  \n",
    "- $X_i$: Point coordinates  \n",
    "- $\\mu$: Mean of the dataset (center of the point cloud)\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Eigenvectors and Eigenvalues\n",
    "\n",
    "- The covariance matrix is decomposed into eigenvectors and eigenvalues:\n",
    "  - **Eigenvectors**: Principal axes of variation (directions in 3D space).\n",
    "  - **Eigenvalues**: Variance along each principal axis (magnitude of variation).\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Dimensionality Reduction\n",
    "\n",
    "PCA selects the top $k$ eigenvectors with the largest eigenvalues, representing the most significant axes of variation.  \n",
    "The data is projected onto these axes, reducing the dimensionality:\n",
    "\n",
    "$$\n",
    "Z = X \\cdot W\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $Z$: Compressed representation of the data  \n",
    "- $W$: Matrix of selected eigenvectors (principal axes)\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Reconstruction\n",
    "\n",
    "To reconstruct the original data, PCA reverses the transformation:\n",
    "\n",
    "$$\n",
    "X' = Z \\cdot W^T + \\mu\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $X'$: Reconstructed data (approximation of $X$)\n",
    "\n",
    "---\n",
    "\n",
    "## Mathematical Insights\n",
    "\n",
    "### Why PCA Works\n",
    "\n",
    "PCA minimizes the **reconstruction error**, which is the difference between the original and reconstructed data.\n",
    "\n",
    "The error is quantified as:\n",
    "\n",
    "$$\n",
    "E = \\|X - X'\\|^2\n",
    "$$\n",
    "\n",
    "PCA ensures $E$ is minimized by using the most significant axes of variation.\n",
    "\n",
    "---\n",
    "\n",
    "### Energy Retention\n",
    "\n",
    "The proportion of variance retained by the selected components is:\n",
    "\n",
    "$$\n",
    "\\text{Energy} = \\frac{\\sum_{i=1}^{k} \\lambda_i}{\\sum_{i=1}^{d} \\lambda_i}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $k$: Number of selected components  \n",
    "- $d$: Total number of dimensions (3 for point clouds)  \n",
    "- $\\lambda_i$: Eigenvalue of the $i$-th component  \n",
    "\n",
    "---\n",
    "\n",
    "### Interpretation of Components\n",
    "\n",
    "- The first principal component corresponds to the direction of maximum variance.\n",
    "- Subsequent components are orthogonal to the previous ones and capture decreasing variance.\n",
    "\n",
    "---\n",
    "\n",
    "## Results and Observations\n",
    "\n",
    "1. **Compression Ratio**:  \n",
    "   PCA achieves compression by representing the point cloud with mean and principal components instead of absolute positions.\n",
    "\n",
    "2. **Visual Fidelity**:  \n",
    "   The reconstructed point cloud may lose minor details but retains the overall structure.\n",
    "\n",
    "3. **Parameter Sensitivity**:  \n",
    "   The choice of components ($k$) and precision for storing eigenvectors and transformed points affects compression and quality.\n",
    "\n",
    "4. **Applications**:  \n",
    "   PCA is widely used in:\n",
    "   - Data visualization (reducing 3D data to 2D for display).\n",
    "   - Noise reduction by discarding minor components.\n",
    "   - Efficient storage and transmission of large datasets.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open3d_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
